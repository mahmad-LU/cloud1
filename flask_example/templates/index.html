{% extends 'base.html' %}
{% block content %}
    <h1 style='color:red'>{% block title %} Welcome to CS4111 - Group 8 {% endblock %}</h1>
        <h1 style='color:red'>Human Activity Recognition with Smartphones </h1>

    <h2 style='color:blue'>The Human Activity Recognition database was built from the recordings of 30 study
    participants performing activities of daily living (ADL) while carrying a waist-mounted
    smartphone with embedded inertial sensors. <em>The objective is to
        classify activities into one of the six activities performed</em>.</h2>
<p></p>
<h2>Description of experiment</h2>
<p>The experiments have been carried out with a group of 30 volunteers with
in an age bracket of 19-48 years. Each person performed six activities (WALKING,
    WALKING<em>UPSTAIRS, WALKING</em>DOWNSTAIRS, SITTING, STANDING, LAYING)
    wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded
    accelerometer and gyroscope, we captured 3-axial linear acceleration and
    3-axial angular velocity at a constant rate of 50Hz. The experiments have
    been video-recorded to label the data manually. The obtained dataset has been
    randomly partitioned into two sets, where 70% of the volunteers was selected
    for generating the training data and 30% the test data. </p>
<p>The sensor signals (accelerometer and gyroscope) were pre-processed by
    applying noise filters and then sampled in fixed-width sliding windows of
    2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal,
    which has gravitational and body motion components, was separated using
    a Butterworth low-pass filter into body acceleration and gravity. The gravitational
    force is assumed to have only low frequency components, therefore
    a filter with 0.3 Hz cutoff frequency was used. From each window, a vector
    of features was obtained by calculating variables from the time and frequency
    domain.</p>
<h2>Attribute information</h2>
<p>For each record in the dataset the following is provided: </p>
<ul>
<li><p>Triaxial acceleration from the accelerometer (total acceleration) an
d the estimated body acceleration. </p></li>
<li><p>Triaxial Angular velocity from the gyroscope. </p></li>
<li><p>A 561-feature vector with time and frequency domain variables. </p><
/li>
<li><p>Its activity label. </p></li>
<li><p>An identifier of the subject who carried out the experiment.</p></li>
</ul>
<h2>Relevant papers</h2>
<p>Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz.
    Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly
    Support Vector Machine. <em>International Workshop of Ambient Assisted Living (IWAAL 2012)</em>.
    Vitoria-Gasteiz, Spain. Dec 2012 </p>
<p>Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra, Jorge L. Reyes-Ortiz.
    Energy Efficient Smartphone-Based Activity Recognition using Fixed-Point Arithmetic.
    <em>Journal of Universal Computer Science. Special Issue in Ambient Assisted Living: Home Care</em>.
    Volume 19, Issue 9. May 2013</p>
    <p>Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz.
        Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly
        Support Vector Machine. 4th International Workshop of Ambient Assited Living,
        IWAAL 2012, Vitoria-Gasteiz, Spain, December 3-5, 2012.
    <em>Proceedings. Lecture Notes in Computer Science</em> 2012, pp 216-223. </p>
<p>Jorge Luis Reyes-Ortiz, Alessandro Ghio, Xavier Parra-Llanas, Davide Anguita,
    Joan Cabestany, Andreu Catala. Human Activity and Motion Disorder
    Recognition: Towards Smarter Interactive Cognitive Environments.
    <em>21st  European Symposium on Artificial Neural Networks, Computational Intelligence
        and Machine Learning, ESANN</em> 2013. Bruges, Belgium 24-26 April 2013.
</p>
<h2>Citation</h2>
<p>Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz.
    A Public Domain Dataset for Human Activity Recognition Using Smartphones.
    <em>21st European Symposium on Artificial Neural Networks, Computational
        Intelligence and Machine Learning, ESANN</em> 2013. Bruges, Belgium 24-26 April 2013.</p>

{% endblock %}